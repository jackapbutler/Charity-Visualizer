{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "ann_reports = pd.read_csv(\"../Charity_Data/Raw/annual-reports-15012021.csv\")\n",
    "pub_reg = pd.read_csv(\"../Charity_Data/Raw/public-register-15012021.csv\").drop(['Unnamed: 11'], axis=1)\n",
    "\n",
    "benefacts = pd.read_csv('../Charity_Data/Raw/benefacts_2021012.csv').drop_duplicates(subset=\"CRA\", keep='first')[['CRA', 'County', 'Registered Address']]\n",
    "benefacts.columns = ['Registered Charity Number', 'Benefact_county', 'Benefact_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-f3914586d73b>, line 134)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-f3914586d73b>\"\u001b[1;36m, line \u001b[1;32m134\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def merge_datasets(annual_reports, public_registry):\n",
    "    global all_regulator \n",
    "    all_regulator = annual_reports.merge(public_registry, on='Registered Charity Number', how='left').drop(['Registered Charity Name_y'], axis=1).rename(columns={\"Registered Charity Name_x\": \"Registered Charity Name\"}).reset_index(drop=True)\n",
    "    print(\"MERGE DATASET SUCCESS\")\n",
    "    print(\".............\")\n",
    "\n",
    "\n",
    "def include_missing_purpose(data):\n",
    "    data.loc[(data['Report Activity'].str.contains(\"Religious activities\") | data['Beneficiaries'].str.contains(\"Religious|Religion|Priests\")) & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Advancement of religion\"\n",
    "    \n",
    "    data.loc[data['Report Activity'].str.contains(\"Promotion of community\") & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Advancement of community development, including rural or urban regeneration\"\n",
    "    \n",
    "    data.loc[data['Report Activity'].str.contains(\"Promotion of health\") & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Promotion of health, including the prevention or relief of sickness, disease or human suffering\"\n",
    "    \n",
    "    data.loc[data['Report Activity'].str.contains(\"Advancement of Arts|Cultural promotion\") & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Advancement of the arts, culture, heritage or sciences\"\n",
    "    \n",
    "    data.loc[data['Report Activity'].str.contains(\"Animal welfare\") & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Prevention or relief of suffering of animals\"\n",
    "    \n",
    "    data.loc[(data['Report Activity'].str.contains(\"Welfare/benevolent|Provision of accommodation/housing|Welfare of those in need|Disability support\")) & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Advancement of community welfare including the relief of those in need by reason of youth, age, ill-health, or disability\"\n",
    "    \n",
    "    data.loc[(data['Report Activity'].str.contains(\"Education|Research/evaluation|Playgroup/afterschool\") | data['Beneficiaries'].str.contains(\"University|School|College\")) & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Advancement of education\"\n",
    "\n",
    "    data.loc[(data['Report Activity'].str.contains(\"Relief of poverty|Overseas aid/famine relief\")) & data['Charitable Purpose'].isnull(), \"Charitable Purpose\"] = \"Relief of poverty or economic hardship\"\n",
    "\n",
    "    if(len(data[data['Charitable Purpose'].isna()]) > 0):\n",
    "        print(\"INCLUDE MISSING PURPOSE FAILED\")\n",
    "        print(\"These are the rows without a recoverable match\")\n",
    "        print(data[data['Charitable Purpose'].isna()])\n",
    "        print(\".............\")\n",
    "    else:\n",
    "        print(\"INCLUDE MISSING PURPOSE SUCCESS\")\n",
    "        print(\".............\")\n",
    "\n",
    "\n",
    "def condense_purpose(data):\n",
    "    \n",
    "    split_purposes = data['Charitable Purpose'].str.split(';', expand=True).fillna('')\n",
    "    num_cols = len(split_purposes.columns)\n",
    "\n",
    "    edu_vals = ('Advancement of education', ' Advancement of education')\n",
    "    com_vals = ('Advancement of community development', ' Advancement of community development', ' Other purpose that is of benefit to the community', 'Other purpose that is of benefit to the community', 'Advancement of community welfare including the relief of those in need by reason of youth, age, ill-health, or disability', ' Advancement of community welfare including the relief of those in need by reason of youth, age, ill-health, or disability', 'Advancement of community development, including rural or urban regeneration', ' Advancement of community development, including rural or urban regeneration')\n",
    "    ani_env_vals = ('Prevention or relief of suffering of animals', ' Prevention or relief of suffering of animals', 'Advancement of environmental sustainability', ' Advancement of environmental sustainability', 'Protection of the natural environment', ' Protection of the natural environment')\n",
    "    arts_vals = ('Advancement of the arts, culture, heritage or sciences', ' Advancement of the arts, culture, heritage or sciences')\n",
    "    prop_vals = (' Advancement of the efficient and effective use of the property of charitable organisations', 'Advancement of the efficient and effective use of the property of charitable organisations')\n",
    "    conf_vals = ('Advancement of conflict resolution or reconciliation', ' Advancement of conflict resolution or reconciliation')\n",
    "    rel_vals = (' Advancement of religion', 'Advancement of religion')\n",
    "    soc_vals = ('Integration of those who are disadvantaged, and the promotion of their full participation, in society', ' Integration of those who are disadvantaged, and the promotion of their full participation, in society')\n",
    "    civic_vals = ('Promotion of civic responsibility or voluntary work', ' Promotion of civic responsibility or voluntary work')\n",
    "    health_vals = ('Promotion of health, including the prevention or relief of sickness, disease or human suffering', ' Promotion of health, including the prevention or relief of sickness, disease or human suffering')\n",
    "    racism_vals = (' Promotion of religious or racial harmony and harmonious community relations', 'Promotion of religious or racial harmony and harmonious community relations')\n",
    "    pov_vals = ('Relief of poverty or economic hardship', ' Relief of poverty or economic hardship')\n",
    "    \n",
    "    for i in range(0, num_cols):\n",
    "        indexed_col = split_purposes[i]\n",
    "\n",
    "        indexed_col[indexed_col.isin(edu_vals)] = \"Education\"\n",
    "        indexed_col[indexed_col.isin(com_vals)] = \"Community\"\n",
    "        indexed_col[indexed_col.isin(ani_env_vals)] = \"Animals / Environment\"\n",
    "        indexed_col[indexed_col.isin(arts_vals)] = \"Arts\"\n",
    "        indexed_col[indexed_col.isin(prop_vals)] = \"Property\"\n",
    "        indexed_col[indexed_col.isin(conf_vals)] = \"Conflict\"\n",
    "        indexed_col[indexed_col.isin(rel_vals)] = \"Religion\"\n",
    "        indexed_col[indexed_col.isin(soc_vals)] = \"Society\"\n",
    "        indexed_col[indexed_col.isin(civic_vals)] = \"Civic Duty\"\n",
    "        indexed_col[indexed_col.isin(health_vals)] = \"Health\"    \n",
    "        indexed_col[indexed_col.isin(racism_vals)] = \"Racism\"\n",
    "        indexed_col[indexed_col.isin(pov_vals)] = \"Poverty\"\n",
    "\n",
    "    data['Purpose'] = split_purposes.apply(' '.join, axis=1)\n",
    "\n",
    "    options = 'Education|Community|Animals / Environment|Arts|Property|Conflict|Religion|Society|Civic Duty|Health|Racism|Poverty'\n",
    "    num_matches = len(data['Purpose'].str.contains(options).value_counts())\n",
    "    num_failed = len(data)-num_matches\n",
    "\n",
    "    if(num_matches > 1):\n",
    "        print(\"CONDENSE PURPOSE FAILED\") \n",
    "        print(\"There are \"+str(num_failed)+\" rows without a condensable purpose, here are the long-form purposes:\")\n",
    "        print(data[~data['Purpose'].str.contains(options)]['Purpose'])\n",
    "        print(\".............\")\n",
    "    else:\n",
    "        print(\"CONDENSE PURPOSE SUCCESS\")\n",
    "        print(\".............\")\n",
    "\n",
    "\n",
    "def split_datasets(data):\n",
    "    data['Registered Charity Number'] = data['Registered Charity Number'].apply(str)\n",
    "    fin_cols = ['Registered Charity Number', 'Financial: Income from Central Government or Local Authorities',\n",
    "       'Financial: Income from other public bodies',\n",
    "       'Financial: Income from philantrophic organisations',\n",
    "       'Financial: Income from donations',\n",
    "       'Financial: Income from trading and commercial activities',\n",
    "       'Financial: Income from other sources', 'Financial: Gross Income',\n",
    "       'Financial: Gross Expenditure', 'Financial: Gross Income (Schools)',\n",
    "       'Financial: Gross Expenditure (Schools)']\n",
    "    gen_cols = ['Registered Charity Number', 'Registered Charity Name', 'Report Size',\n",
    "       'Period Start Date', 'Period End Date', 'Report Activity',\n",
    "       'Activity Description', 'Beneficiaries', 'Number of Volunteers',\n",
    "       'Status', 'Also Known As', 'Primary Address', 'Governing Form',\n",
    "       'CHY Number', 'CRO Number', 'Country Established', 'Charitable Purpose',\n",
    "       'Charitable Objects', 'Purpose']\n",
    "\n",
    "    global fin_data \n",
    "    global gen_data\n",
    "    fin_data = data[fin_cols].reset_index(drop=True)\n",
    "    gen_data = data[gen_cols].drop_duplicates(subset='Registered Charity Number', keep='first').reset_index(drop=True).merge(benefacts, on='Registered Charity Number', how='left') \n",
    "\n",
    "    new_cols = len(gen_data.columns)+len(fin_data.columns)\n",
    "    old_cols = len(data.columns)+len(benefacts.columns)\n",
    "\n",
    "    if(new_cols != old_cols):\n",
    "        print(\"SPLIT DATASET FAILED\")\n",
    "        print(\"Mismatched Number of Columns comparing \"+str(new_cols)+\" in the new DFs to \"+str(old_cols)+\" old DFs.\")\n",
    "    else:\n",
    "        print(\"SPLIT DATASET SUCCESS\")\n",
    "        print(\".............\")\n",
    "\n",
    "\n",
    "def save_json_datasets():\n",
    "    gen_data.to_json('../Charity_Data/Clean/general_data.json')\n",
    "    fin_data.to_json('../Charity_Data/Clean/fin_data.json')\n",
    "    print(\"SUCCESSFULLY SAVED JSON TO LOCAL DRIVE\")\n",
    "\n",
    "\n",
    "def find_coords(data):\n",
    "    geolocator = Nominatim(user_agent=\"jack_charity\")\n",
    "    data['Longitude'] = 'Unsure'\n",
    "    data['Latitude'] = 'Unsure'\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        try:\n",
    "            location = geolocator.geocode(data['Benefact_county'][i])\n",
    "            data['Longitude'][i] = location.longitude\n",
    "            data['Latitude'][i] = location.latitude\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    exp_successes = len(data)-len(data[data['Benefact_county'].isna()])\n",
    "    act_successes = len(data)-len(data[data['Latitude'].isna()])\n",
    "\n",
    "    if(exp_successes != act_successes):\n",
    "        print(\"FINDING COORDINATES FAILED\")\n",
    "        print(\".............\")\n",
    "    else:\n",
    "        print(\"FINDING COORDINATES SUCCESS\")\n",
    "        print(\".............\")\n",
    "\n",
    "    print(str(len(data[data['Benefact_county'].isna()]))+\" of the \"+str(len(data))+\" charities have been removed due to missing counties.\")\n",
    "    data = data.dropna(subset=['Benefact_county'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MERGE DATASET SUCCESS\n",
      ".............\n",
      "INCLUDE MISSING PURPOSE SUCCESS\n",
      ".............\n",
      "CONDENSE PURPOSE SUCCESS\n",
      ".............\n",
      "SPLIT DATASET SUCCESS\n",
      ".............\n",
      "FINDING COORDINATES FAILED\n",
      ".............\n",
      "518 of the 8713 charities have been removed.\n"
     ]
    }
   ],
   "source": [
    "merge_datasets(ann_reports, pub_reg)\n",
    "include_missing_purpose(all_regulator)\n",
    "condense_purpose(all_regulator)\n",
    "split_datasets(all_regulator)\n",
    "find_coords(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'save_json_datasets' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b1e238ef8ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_json_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_json_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "save_json_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'normalize'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-20e0a539ee1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgeneral\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data/Clean/general_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'normalize'"
     ]
    }
   ],
   "source": [
    "general = pd.read_csv('./Data/Clean/general_data.csv')\n",
    "pd.normalize(general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-153f86e1f2ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneral\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-153f86e1f2ae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneral\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "json = ge\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}